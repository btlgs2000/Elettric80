{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elettric80_prima_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQPZ82ISyjgG"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfPTT9Jcz-vi"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-2UN3I60jhi"
      },
      "source": [
        "plt.imshow(x_train[1], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhygRApgPFpC"
      },
      "source": [
        "x_train = (x_train / 255).astype(np.float32)\n",
        "x_test = (x_test / 255).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiwgsR9OKWz2"
      },
      "source": [
        "class MLP:\n",
        "    def __init__(self):\n",
        "        # 784 -> 200 -> 200 -> 10\n",
        "        self.W1 = tf.Variable(tf.random.normal(shape=(200, 784), mean=0.0, stddev=1 / math.sqrt(784)))\n",
        "        self.b1 = tf.Variable(tf.zeros((200, 1)))\n",
        "        self.W2 = tf.Variable(tf.random.normal(shape=(200, 200), mean=0.0, stddev=1 / math.sqrt(200)))\n",
        "        self.b2 = tf.Variable(tf.zeros((200, 1)))\n",
        "        self.W3 = tf.Variable(tf.random.normal(shape=(10, 200), mean=0.0, stddev=1 / math.sqrt(200)))\n",
        "        self.b3 = tf.Variable(tf.zeros((10, 1)))\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [self.W1, self.b1, self.W2, self.b2, self.W3, self.b3]\n",
        "\n",
        "    def call(self, x):\n",
        "        # x.shape =   784 x batch_size\n",
        "\n",
        "        z1 = self.W1 @ x + self.b1\n",
        "        a1 = tf.sigmoid(z1) # 200 x batch_size\n",
        "        z2 = self.W2 @ a1 + self.b2\n",
        "        a2 = tf.sigmoid(z2) # 200 x batch_size\n",
        "        z3 = self.W3 @ a2 + self.b3\n",
        "        y_hat = tf.math.softmax(z3) # 200 x batch_size\n",
        "        return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIH7EbbtNgR3"
      },
      "source": [
        "mlp = MLP()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AM8asbW6YaZ"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    num_equals = tf.reduce_sum(tf.cast(tf.math.equal(y_true, y_pred), dtype=tf.float32))\n",
        "    num_all = tf.cast(tf.size(y_true), dtype=tf.float32)\n",
        "    return (num_equals / num_all).numpy().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeV4hNNaNkZD"
      },
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "ALPHA = 1e-2\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"inizio l'epoca {epoch+1}\")\n",
        "    for i in range(0, 60_000, BATCH_SIZE):\n",
        "        # compone il  batch\n",
        "        x_batch = x_train[i:i+BATCH_SIZE]\n",
        "        y_batch = y_train[i:i+BATCH_SIZE]\n",
        "\n",
        "        # passo forward\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_batch_hat = mlp.call(tf.transpose(tf.reshape(x_batch, shape=(BATCH_SIZE, -1)), perm=(1,0)))\n",
        "            losses = tf.keras.losses.sparse_categorical_crossentropy(y_batch, y_batch_hat, axis=0)\n",
        "            mean_loss = tf.reduce_mean(losses)\n",
        "        \n",
        "        if (i//BATCH_SIZE)%200 == 0:\n",
        "            print(mean_loss.numpy().item())\n",
        "\n",
        "        # calcolo del gradiente\n",
        "        grads = tape.gradient(mean_loss, mlp.get_weights())\n",
        "\n",
        "        # mini-batch gradient descent\n",
        "        for weight, grad in zip(mlp.get_weights(), grads):\n",
        "            weight.assign(weight - ALPHA*grad)\n",
        "\n",
        "    # fine dell'epoca. Valuto l'accuratezza sul test set\n",
        "    y_test_hat = mlp.call(tf.transpose(tf.reshape(x_test, shape=(10_000, -1)), perm=(1,0)))\n",
        "    test_preds = tf.argmax(y_test_hat)\n",
        "    acc = accuracy(tf.cast(y_test, dtype=tf.int64), test_preds)\n",
        "    print(f'accuratezza sul test set = {acc}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}